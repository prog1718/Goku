{"cells":[{"metadata":{"_uuid":"68d558e7-86ba-43a9-b476-bae0d744a663","_cell_guid":"f50813e4-d92d-41e5-ba46-390784b8fcba","trusted":true},"cell_type":"code","source":"import torch\nimport wandb\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\nimport torch.utils.data as data\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom torchsummary import summary\nfrom scipy.ndimage.filters import convolve\nfrom torch.utils.data import Dataset, DataLoader\nfrom skimage import io, transform\nimport pandas as pd\nimport os\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nepochs = 15\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE=50\n\ntrain_dir = '../input/gtsrb-german-traffic-sign/Train'      ## path to train dataset\ntest_dir = '../input/gtsrb-german-traffic-sign/'            ## path to test dataset\ntest_csv = '../input/gtsrb-german-traffic-sign/Test.csv'    ## path to test.csv\nsave_dir = './'                                             ## path to directory to store trained models\n\n## for creating test dataset\nclass test_dataset(Dataset):\n\n    def __init__(self, test_dir, csv_file, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.data = pd.read_csv(csv_file)\n        self.root_dir = test_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir,self.data.iloc[idx, -1])\n        image = io.imread(img_name)\n        true_lab = self.data.iloc[idx, -2]\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        sample = (image,true_lab)\n\n        return sample\n    \n\nclass LocalContrastNormalization(object):\n\n    def __init__(self, kernel_size=3, mode='constant', cval=0.0):\n        self.kernel_size = kernel_size\n        self.mode = mode\n        self.cval = cval\n        \n    def __call__(self, tensor):\n       \n        return torch.stack([self.func(torch.tensor(batch)) for batch in tensor.tolist()])\n        \n\n    def func(self, tensor):\n    \n        C, H, W = tensor.size()\n        kernel = np.ones((self.kernel_size, self.kernel_size))\n        \n\n        arr = np.array(tensor)\n        local_sum_arr = np.array([convolve(arr[c], kernel, mode=self.mode, cval=self.cval)\n                                  for c in range(C)]) # An array that has shape(C, H, W)\n                                                      # Each element [c, h, w] is the summation of the values\n                                                      # in the window that has arr[c,h,w] at the center.\n        local_avg_arr = local_sum_arr / (self.kernel_size**2) # The tensor of local averages.\n\n        arr_square = np.square(arr)\n        local_sum_arr_square = np.array([convolve(arr_square[c], kernel, mode=self.mode, cval=self.cval)\n                                  for c in range(C)]) # An array that has shape(C, H, W)\n                                                      # Each element [c, h, w] is the summation of the values\n                                                      # in the window that has arr_square[c,h,w] at the center.\n        local_norm_arr = np.sqrt(local_sum_arr_square) # The tensor of local Euclidean norms.\n\n\n        local_avg_divided_by_norm = local_avg_arr / (1e-8+local_norm_arr)\n\n        result_arr = np.minimum(local_avg_arr, local_avg_divided_by_norm)\n        \n        return torch.Tensor(result_arr)\n\n\n\n    def __repr__(self):\n        return self._class.name_ + '(kernel_size={0}, threshold={1})'.format(self.kernel_size, self.threshold)\n    \n    \n## Model architecture defination\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 200, kernel_size=7, padding=2)\n        self.max1 = nn.MaxPool2d(2, stride=2)\n        self.conv2 = nn.Conv2d(200, 250, kernel_size=4, padding=2)\n        self.max2 = nn.MaxPool2d(2, stride=2)\n        self.conv3 = nn.Conv2d(250, 350, kernel_size=4, padding=2)\n        self.max3 = nn.MaxPool2d(2, stride=2)\n        self.local = LocalContrastNormalization()\n        self.conv_drop = nn.Dropout2d(p=0.5)\n        self.fc1 = nn.Linear(350*6*6, 400)\n        self.fc2 = nn.Linear(400, 43)\n\n        # stn1 localizaton net\n        self.localization1 = nn.Sequential(\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(3, 250, kernel_size=5, padding=2),\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(250, 250, kernel_size=5, padding=2),\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),\n        )\n\n        # Regressor for the 3 * 2 affine matrix\n        self.fc_loc1 = nn.Sequential(\n            nn.Linear(250 * 6 * 6, 250),\n            torch.nn.Dropout(0.5),\n            nn.ReLU(True),\n            nn.Linear(250, 3 * 2)\n        )\n\n        # Initialize the weights/bias with identity transformation\n        self.fc_loc1[3].weight.data.zero_()\n        self.fc_loc1[3].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n        \n         # stn2 localizaton net\n        self.localization2 = nn.Sequential(\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(200, 150, kernel_size=5, padding=2),\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(150, 200, kernel_size=5, padding=2),\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),\n        )\n\n        # Regressor for the 3 * 2 affine matrix\n        self.fc_loc2 = nn.Sequential(\n            nn.Linear(200 * 2 * 2, 300),\n            torch.nn.Dropout(0.5),\n            nn.ReLU(True),\n            nn.Linear(300, 3 * 2)\n        )\n\n        # Initialize the weights/bias with identity transformation\n        self.fc_loc2[3].weight.data.zero_()\n        self.fc_loc2[3].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n        \n         # stn3 localizaton net\n        self.localization3 = nn.Sequential(\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(250, 150, kernel_size=5, padding=2),\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(150, 200, kernel_size=5, padding=2),\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),\n        )\n\n        # Regressor for the 3 * 2 affine matrix\n        self.fc_loc3 = nn.Sequential(\n            nn.Linear(200 * 1 * 1, 300),\n            torch.nn.Dropout(0.5),\n            nn.ReLU(True),\n            nn.Linear(300, 3 * 2)\n        )\n\n        # Initialize the weights/bias with identity transformation\n        self.fc_loc3[3].weight.data.zero_()\n        self.fc_loc3[3].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n\n    # stn1\n    def stn1(self, x):\n        xs1 = self.localization1(x)\n        xs1 = xs1.view(-1, 250 * 6 * 6)\n        theta1 = self.fc_loc1(xs1)\n        theta1 = theta1.view(-1, 2, 3)\n\n        grid1 = F.affine_grid(theta1, x.size())\n        x1 = F.grid_sample(x, grid1)\n\n        return x1\n    \n    # stn2\n    def stn2(self, x):\n        xs2 = self.localization2(x)\n        xs2 = xs2.view(-1, 200 * 2 * 2)\n        theta2 = self.fc_loc2(xs2)\n        theta2 = theta2.view(-1, 2, 3)\n\n        grid2 = F.affine_grid(theta2, x.size())\n        x2 = F.grid_sample(x, grid2)\n\n        return x2\n    \n    # stn3\n    def stn3(self, x):\n        xs3 = self.localization3(x)\n        xs3 = xs3.view(-1, 200 * 1 * 1)\n        theta3 = self.fc_loc3(xs3)\n        theta3 = theta3.view(-1, 2, 3)\n\n        grid3 = F.affine_grid(theta3, x.size())\n        x3 = F.grid_sample(x, grid3)\n\n        return x3\n\n    def forward(self, x):\n        # transform the input\n        x = self.stn1(x)\n        x = self.conv_drop(F.relu(self.conv1(x)))\n        x = self.max1(x)\n        x = self.local(x).to(device)\n        \n        x = self.stn2(x)\n        x = self.conv_drop(F.relu(self.conv2(x)))\n        x = self.max2(x)\n        x = self.local(x).to(device)\n        \n        x = self.stn3(x)\n        x = self.conv_drop(F.relu(self.conv3(x)))\n        x = self.max3(x)\n        x = self.local(x).to(device)\n        \n        x = x.view(-1, 350*6*6)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return x\n\n## transforms for train data\ntrans = transforms.Compose([\n    transforms.Resize((48,48)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0,0,0], std=[1,1,1])\n])\n\n## transforms for test data\n\ntest_trans = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((48,48)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0,0,0], std=[1,1,1])\n])\n\ntr_data = datasets.ImageFolder(train_dir,transform = trans)\ntrain_data_loader = data.DataLoader(tr_data, batch_size=BATCH_SIZE, shuffle=True)\ntest_data = test_dataset(test_dir,test_csv,transform = test_trans)\ntest_data_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n\nmodel = Net().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n\ndef train(dataloader, model, criterion, optimizer):\n    size = len(dataloader.dataset)\n    preds=[]\n    true=[]\n    tot_loss=0\n    \n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = criterion(pred, y)\n        tot_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        z = F.softmax(pred,dim=1)\n        z = torch.argmax(z,dim=1)\n        preds += z.tolist()\n        true += y.tolist()\n\n        if batch % 100 == 0:\n            print('batch : {} = loss : {}'.format(batch+1,loss.item()))\n    \n    accuracy = accuracy_score(true,preds)\n    tot_loss = tot_loss/(batch+1)     \n    return (tot_loss,accuracy)\n\ndef test(dataloader, model):\n    size = len(dataloader.dataset)\n    model.eval()\n    test_loss, correct = 0, 0\n    preds=[]\n    true=[]\n    with torch.no_grad():\n        for batch,data in enumerate(test_data_loader):\n            X = data[0].to(device)\n            y = data[1].to(device)\n            pred = model(X)\n            test_loss += criterion(pred, y).item()\n            z = F.softmax(pred,dim=1)\n            z = torch.argmax(z,dim=1)\n            preds += z.tolist()\n            true += y.tolist()\n            \n    test_accuracy = accuracy_score(true,preds)\n    test_loss /= (batch+1)\n    return (test_loss,test_accuracy)\n\n## Training......................\n\nepoch_loss=[]\nacc_list=[]\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loss,train_accuracy = train(train_data_loader, model, criterion, optimizer)\n    \n    print('accuracy : {}'.format(100*train_accuracy))\n    print('epoch loss : {}'.format(train_loss))\n    \n    test_loss,test_accuracy = test(test_data_loader, model)\n    epoch_loss.append({'train loss':train_loss,'test loss':test_loss})\n    acc_list.append({'train acc':train_accuracy,'test acc':test_accuracy})\n     \n    print(f\"Test Error: \\n Accuracy: {(100*test_accuracy):>0.1f}, Avg loss: {test_loss:>8f} \\n\")\n    torch.save(model, os.path.join(save_dir,f'model_ep{t+1}.pt'))\n\nprint(\"Training Done!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}